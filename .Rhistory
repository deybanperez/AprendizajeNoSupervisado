sum_diagonal = function(matrix)
{
returnValue = 0;
for (i in 1:nrow(matrix))
{
returnValue = returnValue + matrix[i,i]
}
return(returnValue)
}
#Function to calculate the hit rate, miss rate
confusion_matrix_evaluation = function(confusionMatrix, dataSet)
{
hits = sum_diagonal(confusionMatrix)
hits
hitRate = hits / nrow(dataSet) * 100
missRate = 100 - hitRate
write(sprintf("Tasa de acierto: %f", hitRate), stdout())
write(sprintf("Tasa de fallo: %f", missRate), stdout())
}
#Confusion matrix convertion
confusion_matrix_convertion = function(df, model)
{
matrix = table(True = df$V3, Prediction = model$cluster)
return(matrix[, max.col(matrix)])
}
confusion_matrix_convertion_hclust = function(df, model)
{
matrix = table(True = df$V3, Prediction = model)
return(matrix[, max.col(matrix)])
}
#Preprocessing function
pre_processing = function(df)
{
df$V3 = as.numeric(df$V3)
df$V3[df$V3 == 2] = 3
df$V3[df$V3 == 1] = 2
df$V3[df$V3 == 0] = 1
return(df)
}
pre_processing_especial = function(df)
{
df$V11 = as.numeric(df$V11)
df$V11[df$V11 == 1] = 2
df$V11[df$V11 == 0] = 1
return(df)
}
#####################
#Intsalling Packages#
#####################
install("rgl")
###################
#Loading Libraries#
###################
library(rgl)
df_s = read.csv("s.csv",header = F)
df_s$class = 7*(df_s$V4-min(df_s$V4))/(max(df_s$V4)-min(df_s$V4))+1
plot3d(x = df_s$V1, y = df_s$V2, z = df_s$V3, type = "s" ,col = df_s$class)
model_kmeans_guess = eval_kmeans(df = df_guess, cstart = 1, cfinish = 2, k = 5, dataname = "guess.csv"))
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = model_kmeans$cluster, xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set","h.csv"), collapse = " "))
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
eval_kmeans_3D = function(df, cstart, cfinish, k, dataname)
{
model_kmeans = kmeans(x = df[, cstart:cfinish], centers = k)
plot3d(x = df$V1, y = df$V2, z = df$V3, type = "s" ,col = df$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set",dataname), collapse = " "))
spheres3d(model_kmeans$centers[,c("V1", "V2", "V3")], radius = 5,
col = 1:7)
return(model_kmeans)
}
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
model_kmeans_h = eval_kmeans(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = model_kmeans$cluster, xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set","h.csv"), collapse = " "))
eval_kmeans_3D = function(df, cstart, cfinish, k, dataname)
{
model_kmeans = kmeans(x = df[, cstart:cfinish], centers = k)
plot3d(x = df$V1, y = df$V2, z = df$V3, type = "s" ,col = model_kmeans$cluster, xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set",dataname), collapse = " "))
spheres3d(model_kmeans$centers[,c("V1", "V2", "V3")], radius = 5,
col = 1:7)
return(model_kmeans)
}
model_kmeans_h = eval_kmeans(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
model_kmeans = kmeans(x = df_h[, 1:3], centers = 7)
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = model_kmeans$cluster,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set","h.csv"), collapse = " "))
eval_kmeans_3D = function(df, cstart, cfinish, k, dataname)
{
model_kmeans = kmeans(x = df[, cstart:cfinish], centers = k)
plot3d(x = df$V1, y = df$V2, z = df$V3, type = "s" ,col = model_kmeans$cluster,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = paste(c("Data Set",dataname), collapse = " "))
spheres3d(model_kmeans$centers[,c("V1", "V2", "V3")], radius = 5,
col = 1:7)
return(model_kmeans)
}
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
model_kmeans_h = eval_kmeans(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
x1 = c(0, 0)
x2 = c(10, 10)
dist(cbind(x1,x2))
x1 = c(0, 0, 0)
x2 = c(10, 10, 10)
dist(cbind(x1,x2))
dist(rbind(x1,x2))
x1 = c(0, 0)
x2 = c(10, 10)
dist(rbind(x1,x2))
df_h$distance[model_kmeans_h$centers == 1]
df_h$distance[model_kmeans_h$centers == 1]
df_h$distance[model_kmeans_h$cluster == 1]
model_kmeans_h$cluster
model_kmeans_h$cluster == 1
df_h$distance[model_kmeans_h$cluster == 1]
model_kmeans_h$cluster == 1
model_kmeans_h$cluster == 1
model_kmeans_h$centers[1]
model_kmeans_h$centers[2]
model_kmeans_h$centers[1,1]
model_kmeans_h$centers[1,2]
model_kmeans_h$centers[1,3]
table_model_kmeans_h = confusion_matrix_convertion(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
confusion_matrix_convertion_3D = function(df, model)
{
matrix = table(True = df$class, Prediction = model)
return(matrix[, max.col(matrix)])
}
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
df_h = read.csv("h.csv",header = F)
df_h$class = 8*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 8, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
confusion_matrix_convertion_3D = function(df, model)
{
matrix = table(True = df$class, Prediction = model$cluster)
return(matrix[, max.col(matrix)])
}
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
#Aplying algorithms
#########
#K-Means#
#########
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
View(df_h)
df_h$V4 = floor(df_h$V4)
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
#Aplying algorithms
#########
#K-Means#
#########
df_h$class = floor(df_h$class)
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
confusion_matrix_evaluation(table_model_kmeans_moon, df_moon)
confusion_matrix_evaluation(table_model_kmeans_h, df_h)
df_h = read.csv("h.csv",header = F)
df_h$class = 8*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
#Aplying algorithms
#########
#K-Means#
#########
df_h$class = floor(df_h$class)
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 8, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
#Aplying algorithms
#########
#K-Means#
#########
df_h$class = floor(df_h$class)
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
confusion_matrix_evaluation(table_model_kmeans_h, df_h)
sum_diagonal(table_model_kmeans_h)
sum_diagonal(table_model_kmeans_h) / nrow(df_h) * 100
df_s = read.csv("s.csv",header = F)
df_s$class = 7*(df_s$V4-min(df_s$V4))/(max(df_s$V4)-min(df_s$V4))+1
input_hierarchical_h = df_h
input_hierarchical_h$V3 = NULL
input_hierarchical_h$class = NULL
input_hierarchical_h = as.matrix(input_hierarchical_h)
hierarchical_distance_h = dist(input_hierarchical_h)
eval_hclust_3d = function(distance, mode, centroids, input, dataname)
{
model = hclust(distance, method = mode)
model_cut= cutree(model, k = centroids)
plot3d(x = input[,1], y = input[,2], z = input[,3], type = "s",
main = paste(c("Data set", dataname), collapse = " "), sub = paste(c(mode,"H-Clust Algorithm"), collapse = " "),
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
col = model_cut)
return(model_cut)
}
model_hierarchical_single_h = eval_hclust_3d(distance = hierarchical_distance_h, mode = "single", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
model_hierarchical_single_h = eval_hclust_3d(distance = hierarchical_distance_h, mode = "complete", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
model_hierarchical_single_h = eval_hclust_3d(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
View(confusion_matrix_convertion_3D)
View(confusion_matrix_convertion_3D)
confusion_matrix_convertion_hclust_3D = function(df, model)
{
matrix = table(True = df$V3, Prediction = model)
return(matrix[, max.col(matrix)])
}
confusion_matrix_convertion_hclust_3D = function(df, model)
{
matrix = table(True = df$class, Prediction = model)
return(matrix[, max.col(matrix)])
}
eval_hclust_3D = function(distance, mode, centroids, input, dataname)
{
model = hclust(distance, method = mode)
model_cut= cutree(model, k = centroids)
plot3d(x = input[,1], y = input[,2], z = input[,3], type = "s",
main = paste(c("Data set", dataname), collapse = " "), sub = paste(c(mode,"H-Clust Algorithm"), collapse = " "),
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
col = model_cut)
return(model_cut)
}
model_hierarchical_single_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_single_moon = confusion_matrix_convertion_hclust_3D(df = df_moon, model = model_hierarchical_single_moon)
table_model_hierarchical_single_h = confusion_matrix_convertion_hclust_3D(df = df_h, model = model_hierarchical_single_h)
table_model_hierarchical_single_h
model_hierarchical_single_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "single", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_single_h = confusion_matrix_convertion_hclust_3D(df = df_h, model = model_hierarchical_single_h)
table_model_hierarchical_single_h
input_hierarchical_h = df_h
input_hierarchical_h$V4 = NULL
input_hierarchical_h$class = NULL
input_hierarchical_h = as.matrix(input_hierarchical_h)
hierarchical_distance_h = dist(input_hierarchical_h)
model_hierarchical_single_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "single", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table(df_h$class, model_hierarchical_single_h)
table_model_hierarchical_single_h = table(True = df_h$class, Prediction = model_hierarchical_single_h)
table_model_hierarchical_single_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_single_moon, dataSet = df_moon)
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_single_h, dataSet = df_h)
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_single_h, dataSet = df_h - 1)
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_single_h, dataSet = df_h - 1)
nrow(table_model_hierarchical_single_h)
nrow(df_h$class)
df_h$class = floor(df_h$class)
nrow(df_h$class)
table_model_hierarchical_single_h
df_h = read.csv("h.csv",header = F)
df_h$class = floor(df_h$class)
df_h = read.csv("h.csv",header = F)
df_h$class = floor(df_h$class)
df_h = read.csv("h.csv",header = F)
df_h$class = floor(df_h$class)
df_h = read.csv("h.csv",header = F)
df_h$class = 7*(df_h$V4-min(df_h$V4))/(max(df_h$V4)-min(df_h$V4))+1
df_h$class = floor(df_h$class)
df_h$class[df_h$class == 8] = 7
plot3d(x = df_h$V1, y = df_h$V2, z = df_h$V3, type = "s" ,col = df_h$class,
xlab = "Feature 1", ylab = "Feature 2", zlab = "Feature 3",
main = "Data Set h.csv")
model_kmeans_h = eval_kmeans_3D(df = df_h, cstart = 1, cfinish = 3, k = 7, dataname = "h.csv")
table_model_kmeans_h = confusion_matrix_convertion_3D(df = df_h, model = model_kmeans_h)
table_model_kmeans_h
confusion_matrix_evaluation(table_model_kmeans_h, df_h)
input_hierarchical_h = df_h
input_hierarchical_h$V4 = NULL
input_hierarchical_h$class = NULL
input_hierarchical_h = as.matrix(input_hierarchical_h)
hierarchical_distance_h = dist(input_hierarchical_h)
###############
#Single method#
###############
model_hierarchical_single_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "single", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_single_h = table(True = df_h$class, Prediction = model_hierarchical_single_h)
table_model_hierarchical_single_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_single_h, dataSet = df_h )
model_hierarchical_complete_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "complete", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_complete_h = table(True = df_h$class, Prediction = model_hierarchical_complete_h)
table_model_hierarchical_complete_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_complete_h, dataSet = df_h )
confusion_matrix_convertion_3D(df_h, model = model_hierarchical_complete_h)
confusion_matrix_convertion_hclust_3D(df_h, model = model_hierarchical_complete_h)
table_model_hierarchical_complete_h = confusion_matrix_convertion_hclust_3D(df_h, model = model_hierarchical_complete_h)
table_model_hierarchical_complete_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_complete_h, dataSet = df_h )
model_hierarchical_complete_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "complete", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_complete_h = confusion_matrix_convertion_hclust_3D(df_h, model = model_hierarchical_complete_h)
table_model_hierarchical_complete_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_complete_h, dataSet = df_h )
table_model_hierarchical_complete_h = table(True = df_h$class, Prediction = model_hierarchical_complete_h)
table_model_hierarchical_complete_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_complete_h, dataSet = df_h )
model_hierarchical_complete_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "complete", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_complete_h = table(True = df_h$class, Prediction = model_hierarchical_complete_h)
table_model_hierarchical_complete_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_complete_h, dataSet = df_h )
max.col(table_model_hierarchical_complete_h)
max(table_model_hierarchical_complete_h)
max(table_model_hierarchical_complete_h[,])
max(table_model_hierarchical_complete_h[,1])
max(table_model_hierarchical_complete_h[,2])
max(table_model_hierarchical_complete_h[,3])
max(table_model_hierarchical_complete_h[,4])
max(table_model_hierarchical_complete_h[,5])
max(table_model_hierarchical_complete_h[,6])
max(table_model_hierarchical_complete_h[,7])
table_model_hierarchical_complete_h[,]= max(table_model_hierarchical_complete_h[,7])
table_model_hierarchical_complete_h[,]== max(table_model_hierarchical_complete_h[,7])
View(table_model_kmeans_h)
table_model_hierarchical_complete_h[,] == max(table_model_hierarchical_complete_h[,1])
table_model_hierarchical_complete_h[,] == max(table_model_hierarchical_complete_h[,2])
table_model_hierarchical_complete_h[,max(table_model_hierarchical_complete_h[,2])]
which.max(table_model_hierarchical_complete_h[,7])
which.max(table_model_hierarchical_complete_h[,2])
which.max(table_model_hierarchical_complete_h[,1])
which.is.max(table_model_hierarchical_complete_h[,1])
install("nnet")
library(nnet)
which.is.max(table_model_hierarchical_complete_h[,1])
which.is.max(table_model_hierarchical_complete_h[,2])
which.is.max(table_model_hierarchical_complete_h[,3])
which.is.max(table_model_hierarchical_complete_h[,4])
which.is.max(table_model_hierarchical_complete_h[,5])
which.is.max(table_model_hierarchical_complete_h[,6])
which.is.max(table_model_hierarchical_complete_h[,7])
which.is.max(table_model_hierarchical_complete_h[,8])
table_model_hierarchical_complete_h
model_hierarchical_complete_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "complete", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_complete_h = table(True = df_h$class, Prediction = model_hierarchical_complete_h)
which.is.max(table_model_hierarchical_complete_h[,8])
which.is.max(table_model_hierarchical_complete_h[,1])
which.is.max(table_model_hierarchical_complete_h[,2])
which.is.max(table_model_hierarchical_complete_h[,3])
which.is.max(table_model_hierarchical_complete_h[,4])
which.is.max(table_model_hierarchical_complete_h[,5])
which.is.max(table_model_hierarchical_complete_h[,6])
which.is.max(table_model_hierarchical_complete_h[,7])
which.is.max(table_model_hierarchical_complete_h[,])
which.is.max(table_model_hierarchical_complete_h[,1:7])
which.is.max(table_model_hierarchical_complete_h[,1])
which.is.max(table_model_hierarchical_complete_h[,2])
which.is.max(table_model_hierarchical_complete_h[,3])
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_average_h, dataSet = df_h )
which.is.max(table_model_hierarchical_average_h[1,])
a = vector(,length = nrow(table_model_hierarchical_single_h))
a
a = vector(0,length = nrow(table_model_hierarchical_single_h))
a = as.numeric(vector(0,length = nrow(table_model_hierarchical_single_h)))
a = as.numeric(vector(,length = nrow(table_model_hierarchical_single_h)))
a = as.numeric(vector(length = nrow(table_model_hierarchical_single_h)))
a
for(i in i:7)
{
a[i] = which.is.max(i,)
}
for(i in i1:7)
{
a[i] = which.is.max(i,)
}
for(i in 1:7)
{
a[i] = which.is.max(i,)
}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_single_h(i,))
}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h(i,))
}
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
for(i in 1:7)
{}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h(i,))
}
table_model_hierarchical_average_h
for(i in 1:7)
{}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[i,])
}
a
table_model_hierarchical_average_h = table_model_hierarchical_average_h[a]
table_model_hierarchical_average_h
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[i,])
}
a
table_model_hierarchical_average_h
c(a)
table_model_hierarchical_average_h = table_model_hierarchical_average_h[c(a)]
table_model_hierarchical_average_h
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
for (k in 1:30)
{
model_kmeans_guess_jambu = kmeans(df_guess, k)
valor[k] = model_kmeans_guess_jambu$tot.withinss
}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[,i])
}
a
table_model_hierarchical_average_h = table_model_hierarchical_average_h[a]
table_model_hierarchical_average_h
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_average_h, dataSet = df_h )
for (i in 1:7)
{
df_h$distance[model_kmeans_h$centers == i] = dist(rbind(c(model)))
}
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[,i])
}
a
table_model_hierarchical_average_h = table_model_hierarchical_average_h[,a]
table_model_hierarchical_average_h = table_model_hierarchical_average_h[,a]
table_model_hierarchical_average_h
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
confusion_matrix_evaluation(confusionMatrix = table_model_hierarchical_average_h, dataSet = df_h )
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[,i])
}
table_model_hierarchical_average_h = table_model_hierarchical_average_h[,a]
table_model_hierarchical_average_h
model_hierarchical_average_h = eval_hclust_3D(distance = hierarchical_distance_h, mode = "average", centroids = 7, input = input_hierarchical_h, dataname = "h.csv")
table_model_hierarchical_average_h = table(True = df_h$class, Prediction = model_hierarchical_average_h)
table_model_hierarchical_average_h
for(i in 1:7)
{
a[i] = which.is.max(table_model_hierarchical_average_h[i,])
}
table_model_hierarchical_average_h = table_model_hierarchical_average_h[,a]
table_model_hierarchical_average_h
